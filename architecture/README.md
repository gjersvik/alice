# Alice architecture discussion

This folder contains the architecture plans and vision for the Alice project. This is not how it is right now. Its main goal is to help us make decisions about Alice. This document is not set in stone. Sometimes we will need to make pragmatic decisions that will not follow the architecture. But they should have good reasons for it.

We should not write architecture documents for what is over the horizon. Only for what we can see and plan for. And only with the details we can reasonably infer at this time.

Also, architecture is a direction, not a target. So this document will change when the goals, focus, or technology changes.

## Sub pages
- [Roadmap](./Roadmap.md) - The short-term roadmap for Alice.
- [Data Strategy](./data-strategy.md) - How we will handle data in Alice.

## High level vision and goals.
Alice is a personal AI assistant that reacts to events and proposes solutions. These may run as one-off or repeatable tasks. You can also chat with it and teach it your context. It will learn from your conversations and use that to help you.

From an architecture vision, there are a few goals and guiding principles that we will follow.

* Local first.
* Private by default.
* Run it your way.

The big keyword is TRUST. We must build a system that the user can trust and feel in control at all times.

### Local first.
Alice should be fully functional in the browser, not connected to any backend or service.

The user can choose to run a backend or connect to one, which will unlock more features like higher performance, and running tasks and learning in the background when the user is offline.

Even if configured with a backend, Alice should still be able to function when offline.

### Private by default.
The user must be in full control of their data. And not in the "you accept our terms and conditions or we delete your account" way. Every step needs to be an informed consent, with a real choice to say no.

The default must be everything is private. Only when users explicitly choose to share data, will it be shared. That includes tracking and analytics.

Also, if the user wants to trade privacy for performance or convenience, that is their choice. But it must be a clear and informed choice.

### Run it your way.
Any reasonable tech-savvy person should be able to install and operate the Alice backend and integrate it with their own services. This drags the architecture towards a modular monolith, where there are only a handful of services that need to run.

More complex setups should also be possible.

## Configuration and extensibility.
As the goals of Alice are empowering users and having them in control, configuration needs special attention. Giving users 1000 options is not empowering; it is overwhelming.

So I propose we do it in layers, where each layer becomes more complex and specific.
1. The why layer.
2. The what layer.
3. The how layer.
4. Tuning layer.

## The why layer.
This asks: Why are you using Alice? Have a few high-level options and contexts, like:
- I am just looking around.
- Personal assistant in private settings.
- Personal assistant in a work setting.
- Team assistant.

The options here should be few and simple, but high impact with sane defaults.

## The what layer.
This layer is all about what the user wants to do with Alice. What should it connect to? What data should it use? What services should it integrate with?

The options here should focus on outcomes for the user, not how it is done.

## The how layer.
At this layer, the user wants to configure how Alice works and how things are done. This is the layer where we can really show the complexity of the system. A playground for the power users.

## The tuning layer.
This layer is primarily for developers and operators who want to tweak and tune the system. Here we can go nuts with the configuration and have all the knobs and levers to tweak the system. Actually, here more is better.

## Transparency and trust.
Alice should not keep secrets from the user. But, as with configuration, we need to be careful not to overwhelm the user. Pages and pages of raw JSON are not transparent; it's hiding in plain sight.

We should use the same layered approach as with configuration, where the user can drill down into more and more details, but should always start with a simple overview.
1. The what layer.
2. The why layer.
3. The how layer.
4. Debugging layer.

## The what layer.
A simple explanation of what happened. Use LLM to simplify and summarize the events. This is the layer that should be shown to the user by default. It should be simple and easy to understand. No deep knowledge of the system should be needed to understand it.

## The why layer.
The same information as the what layer, but now generated by the system from logs, in a very dry, matter-of-fact way. But still understandable and reasonably high level.

This could be the different prompts that the LLM generated while reasoning, the datasets it used, and the steps it took to come to a conclusion.

## The how layer.
Show everything that the system did: all the prompts, system prompts, all the generated data, and all the steps it took. Nothing is hidden from the user. This is to help the user debug why the assistant did something unexpected.

## Debugging layer.
The raw events, with the raw data as the system saw it. No formatting or processing. This is the layer for the developers and operators who want to see the raw data and events and debug the system.

## Timeline for implementation.

### Dogfooding.
At first, there is only the developer as a user. They are already perfectly empowered and do not need any help with configuration or information about what is going on. So the first version of Alice will not have any of the configuration or transparency layers.

### The first set of users.
The first set of users will most likely be highly technical individuals who are familiar with the developer. We can start to look into the configuration and transparency, but do not sweat it.

### The far future.
We may never get to the point where we need to implement the full configuration and transparency layers. But we should make decisions with them in mind. Bolting on something like this after the fact is a herculean task.